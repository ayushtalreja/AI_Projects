{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0c8b0a8",
   "metadata": {},
   "source": [
    "This is the first version of our checkers model, which we will improve in further versions.\n",
    "\n",
    "**To understand how the model works, how much we achieved with this version i.e, v1 and in corresponding versions, please consult our research paper.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9655fddd",
   "metadata": {},
   "source": [
    "# English Draughts\n",
    "The version of checkers that we are trying to implement in this notebook is [English draughts](https://en.wikipedia.org/wiki/English_draughts), which follows \n",
    "following rules:\n",
    "1. Black plays the first move\n",
    "2. all pieces can only move and capture diagonally\n",
    "3. men can only move/capture diagonally forward\n",
    "4. kings can move/capture in any diagonal direction\n",
    "5. if a man reaches the other side of the board, the turn ends and it becomes a king\n",
    "6. captures are made by moving any piece diagonally over an opponent's\n",
    "if a capture can be made, it must be taken\n",
    "7. mutliple captures can be made in a single turn and with a single piece\n",
    "8. the game ends when a players captures all the opponent's pieces\n",
    "9. a player also wins when the opponent can not make a legal move\n",
    "\n",
    "The game is played on a 8x8 checkerboard and both players have 12 men."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98ef294",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db813274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "from keras.models import model_from_json\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers\n",
    "from keras.models import model_from_json\n",
    "from tqdm import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ac583",
   "metadata": {},
   "source": [
    "### Checkers Game Code\n",
    "\n",
    "The following code is taken from a publicly available [library](https://raw.githubusercontent.com/Btsan/CheckersBot/master/checkers.py\"), which contains all the needed functions for playing the game: possible moves, possible captures, generating next position, check the game winner, and many other useful functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f092ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the number of opponent's captured pieces (max = 12)\n",
    "def num_captured(board):\n",
    "\treturn 12 - np.sum(board < 0)\n",
    "\n",
    "# \n",
    "def num_branches(board, x, y):\n",
    "\tcount = 0\n",
    "\tif (board[x, y] >= 1 and x < 6):\n",
    "\t\tif (y < 6):\n",
    "\t\t\tif (board[x+1, y+1] < 0 and board[x+2, y+2] == 0):\n",
    "\t\t\t\tboard[x+2, y+2] = board[x, y]\n",
    "\t\t\t\tboard[x, y] = 0\n",
    "\t\t\t\ttemp = board[x+1, y+1]\n",
    "\t\t\t\tboard[x+1, y+1] = 0\n",
    "\t\t\t\tcount += num_branches(board, x+2, y+2) + 1\n",
    "\t\t\t\tboard[x+1, y+1] = temp\n",
    "\t\t\t\tboard[x, y] = board[x+2, y+2]\n",
    "\t\t\t\tboard[x+2, y+2] = 0\n",
    "\t\tif (y > 1):\n",
    "\t\t\tif (board[x+1, y-1] < 0 and board[x+2, y-2] == 0):\n",
    "\t\t\t\tboard[x+2, y-2] = board[x, y]\n",
    "\t\t\t\tboard[x, y] = 0\n",
    "\t\t\t\ttemp = board[x+1, y-1]\n",
    "\t\t\t\tboard[x+1, y-1] = 0\n",
    "\t\t\t\tcount += num_branches(board, x+2, y-2) + 1\n",
    "\t\t\t\tboard[x+1, y-1] = temp\n",
    "\t\t\t\tboard[x, y] = board[x+2, y-2]\n",
    "\t\t\t\tboard[x+2, y-2] = 0\n",
    "\tif (board[x, y] == 3 and x > 0):\n",
    "\t\tif (y < 6):\n",
    "\t\t\tif (board[x-1, y+1] < 0 and board[x-2, y+2] == 0):\n",
    "\t\t\t\tboard[x-2, y+2] = board[x, y]\n",
    "\t\t\t\tboard[x, y] = 0\n",
    "\t\t\t\ttemp = board[x-1, y+1]\n",
    "\t\t\t\tboard[x-1, y+1] = 0\n",
    "\t\t\t\tcount += num_branches(board, x-2, y+2) + 1\n",
    "\t\t\t\tboard[x-1, y+1] = temp\n",
    "\t\t\t\tboard[x, y] = board[x-2, y+2]\n",
    "\t\t\t\tboard[x-2, y+2] = 0\n",
    "\t\tif (y > 1):\n",
    "\t\t\tif (board[x-1, y-1] < 0 and board[x-2, y-2] == 0):\n",
    "\t\t\t\tboard[x-2, y-2] = board[x, y]\n",
    "\t\t\t\tboard[x, y] = 0\n",
    "\t\t\t\ttemp = board[x-1, y-1]\n",
    "\t\t\t\tboard[x-1, y-1] = 0\n",
    "\t\t\t\tcount += num_branches(board, x-2, y-2) + 1\n",
    "\t\t\t\tboard[x-1, y-1] = temp\n",
    "\t\t\t\tboard[x, y] = board[x-2, y-2]\n",
    "\t\t\t\tboard[x-2, y-2] = 0\n",
    "\treturn count\n",
    "\n",
    "# Function to calculate number of possible moves at a given position\n",
    "def possible_moves(board):\n",
    "\tcount = 0\n",
    "\tfor i in range(0, 8):\n",
    "\t\tfor j in range(0, 8):\n",
    "\t\t\tif (board[i, j] > 0):\n",
    "\t\t\t\tcount += num_branches(board, i, j)\n",
    "\tif (count > 0):\n",
    "\t\treturn count\n",
    "\tfor i in range(0, 8):\n",
    "\t\tfor j in range(0, 8):\n",
    "\t\t\tif (board[i, j] >= 1 and i < 7):\n",
    "\t\t\t\tif (j < 7):\n",
    "\t\t\t\t\tcount += (board[i+1, j+1] == 0)\n",
    "\t\t\t\tif (j > 0):\n",
    "\t\t\t\t\tcount += (board[i+1, j-1] == 0)\n",
    "\t\t\tif (board[i, j] == 3 and i > 0):\n",
    "\t\t\t\tif (j < 7):\n",
    "\t\t\t\t\tcount += (board[i-1, j+1] == 0)\n",
    "\t\t\t\telif (j > 0):\n",
    "\t\t\t\t\tcount += (board[i-1, j-1] == 0)\n",
    "\treturn count\n",
    "\n",
    "# Function to decide the winner\n",
    "def game_winner(board):\n",
    "\tif (np.sum(board < 0) == 0):\n",
    "\t\treturn 1\n",
    "\telif (np.sum(board > 0) == 0):\n",
    "\t\treturn -1\n",
    "\tif (possible_moves(board) == 0):\n",
    "\t\treturn -1\n",
    "\telif (possible_moves(reverse(board)) == 0):\n",
    "\t\treturn 1\n",
    "\telse:\n",
    "\t\treturn 0\n",
    "\n",
    "def at_enemy(board):\n",
    "\tcount = 0\n",
    "\tfor i in range(5, 8):\n",
    "\t\tcount += np.sum(board[i] == 1) + np.sum(board[i] == 3)\n",
    "\treturn count\n",
    "\n",
    "def at_middle(board):\n",
    "\tcount = 0\n",
    "\tfor i in range(3, 5):\n",
    "\t\tcount += np.sum(board[i] == 1) + np.sum(board[i] == 3)\n",
    "\treturn count\n",
    "\n",
    "def num_men(board):\n",
    "\treturn np.sum(board == 1)\n",
    "\n",
    "def num_kings(board):\n",
    "\treturn np.sum(board == 3)\n",
    "\n",
    "def capturables(board): # possible number of unsupported enemies\n",
    "\tcount = 0\n",
    "\tfor i in range(1, 7):\n",
    "\t\tfor j in range(1, 7):\n",
    "\t\t\tif (board[i, j] < 0):\n",
    "\t\t\t\tcount += (board[i+1, j+1] >= 0 and board[i+1, j-1] >= 0 and  board[i-1, j+1] >= 0 and board[i-1, j-1] >= 0)\n",
    "\treturn count\n",
    "\n",
    "def semicapturables(board): # number of own units with at least one support\n",
    "\treturn (12 - uncapturables(board) - capturables(reverse(board)))\n",
    "\n",
    "def uncapturables(board): # number of own units that can't be captured\n",
    "\tcount = 0\n",
    "\tfor i in range(1, 7):\n",
    "\t\tfor j in range(1, 7):\n",
    "\t\t\tif (board[i, j] > 0):\n",
    "\t\t\t\tcount += ((board[i+1, j+1] > 0 < board[i+1, j-1]) or (board[i-1, j+1] > 0 < board[i-1, j-1]) or (board[i+1, j+1] > 0 < board[i-1, j+1]) or (board[i+1, j-1] > 0 < board[i-1, j-1]))\n",
    "\tcount += np.sum(board[0] == 1) + np.sum(board[0] == 3) + np.sum(board[1:7, 0] == 1) + np.sum(board[1:7, 0] == 3) + np.sum(board[7] == 1) + np.sum(board[7] == 3) + np.sum(board[1:7, 7] == 1) + np.sum(board[1:7, 7] == 3)\n",
    "\treturn count\n",
    "\n",
    "# function to reverse the board\n",
    "def reverse(board):\n",
    "\tb = -board\n",
    "\tb = np.fliplr(b)\n",
    "\tb = np.flipud(b)\n",
    "\treturn b\n",
    "\n",
    "def np_board():\n",
    "\treturn np.array(get_board())\n",
    "\n",
    "def get_board():\n",
    "\treturn [1, 1, 1, 1,  1, 1, 1, 1,  1, 1, 1, 1,  0, 0, 0, 0,  0, 0, 0, 0,  -1, -1, -1, -1,  -1, -1, -1, -1,  -1, -1, -1, -1]\n",
    "\n",
    "def expand(board):\n",
    "\tb = np.zeros((8, 8), dtype='b')\n",
    "\tfor i in range(0, 8):\n",
    "\t\tif (i%2 == 0):\n",
    "\t\t\tb[i] = np.array([0, board[i*4], 0, board[i*4 + 1], 0, board[i*4 + 2], 0, board[i*4 + 3]])\n",
    "\t\telse:\n",
    "\t\t\tb[i] = np.array([board[i*4], 0, board[i*4 + 1], 0, board[i*4 + 2], 0, board[i*4 + 3], 0])\n",
    "\treturn b\n",
    "\n",
    "def compress(board):\n",
    "\tb = np.zeros((1,32), dtype='b')\n",
    "\tfor i in range(0, 8):\n",
    "\t\tif (i%2 == 0):\n",
    "\t\t\tb[0, i*4 : i*4+4] = np.array([board[i, 1], board[i, 3], board[i, 5], board[i, 7]])\n",
    "\t\telse:\n",
    "\t\t\tb[0, i*4 : i*4+4] = np.array([board[i, 0], board[i, 2], board[i, 4], board[i, 6]])\n",
    "\treturn b\n",
    "\n",
    "def generate_branches(board, x, y):\n",
    "\tbb = compress(board)\n",
    "\tif (board[x, y] >= 1 and x < 6):\n",
    "\t\ttemp_1 = board[x, y]\n",
    "\t\tif (y < 6):\n",
    "\t\t\tif (board[x+1, y+1] < 0 and board[x+2, y+2] == 0):\n",
    "\t\t\t\tboard[x+2, y+2] = board[x, y]\n",
    "\t\t\t\tif (x+2 == 7):\n",
    "\t\t\t\t\tboard[x+2, y+2] = 3\n",
    "\t\t\t\ttemp = board[x+1, y+1]\n",
    "\t\t\t\tboard[x+1, y+1] = 0\n",
    "\t\t\t\tif (board[x, y] != board[x+2, y+2]):\n",
    "\t\t\t\t\tboard[x, y] = 0\n",
    "\t\t\t\t\tbb = np.vstack((bb, compress(board)))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tboard[x, y] = 0\n",
    "\t\t\t\t\tbb = np.vstack((bb, generate_branches(board, x+2, y+2)))\n",
    "\t\t\t\tboard[x+1, y+1] = temp\n",
    "\t\t\t\tboard[x, y] = temp_1\n",
    "\t\t\t\tboard[x+2, y+2] = 0\n",
    "\t\tif (y > 1):\n",
    "\t\t\tif (board[x+1, y-1] < 0 and board[x+2, y-2] == 0):\n",
    "\t\t\t\tboard[x+2, y-2] = board[x, y]\n",
    "\t\t\t\tif (x+2 == 7):\n",
    "\t\t\t\t\tboard[x+2, y-2] = 3\n",
    "\t\t\t\ttemp = board[x+1, y-1]\n",
    "\t\t\t\tboard[x+1, y-1] = 0\n",
    "\t\t\t\tif (board[x, y] != board[x+2, y-2]):\n",
    "\t\t\t\t\tboard[x, y] = 0\n",
    "\t\t\t\t\tbb = np.vstack((bb, compress(board)))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tboard[x, y] = 0\n",
    "\t\t\t\tbb = np.vstack((bb, generate_branches(board, x+2, y-2)))\n",
    "\t\t\t\tboard[x+1, y-1] = temp\n",
    "\t\t\t\tboard[x, y] = temp_1\n",
    "\t\t\t\tboard[x+2, y-2] = 0\n",
    "\tif (board[x, y] == 3 and x > 0):\n",
    "\t\tif (y < 6):\n",
    "\t\t\tif (board[x-1, y+1] < 0 and board[x-2, y+2] == 0):\n",
    "\t\t\t\tboard[x-2, y+2] = board[x, y]\n",
    "\t\t\t\tboard[x, y] = 0\n",
    "\t\t\t\ttemp = board[x-1, y+1]\n",
    "\t\t\t\tboard[x-1, y+1] = 0\n",
    "\t\t\t\tbb = np.vstack((bb, generate_branches(board, x-2, y+2)))\n",
    "\t\t\t\tboard[x-1, y+1] = temp\n",
    "\t\t\t\tboard[x, y] = board[x-2, y+2]\n",
    "\t\t\t\tboard[x-2, y+2] = 0\n",
    "\t\tif (y > 1):\n",
    "\t\t\tif (board[x-1, y-1] < 0 and board[x-2, y-2] == 0):\n",
    "\t\t\t\tboard[x-2, y-2] = board[x, y]\n",
    "\t\t\t\tboard[x, y] = 0\n",
    "\t\t\t\ttemp = board[x-1, y-1]\n",
    "\t\t\t\tboard[x-1, y-1] = 0\n",
    "\t\t\t\tbb = np.vstack((bb, generate_branches(board, x-2, y-2)))\n",
    "\t\t\t\tboard[x-1, y-1] = temp\n",
    "\t\t\t\tboard[x, y] = board[x-2, y-2]\n",
    "\t\t\t\tboard[x-2, y-2] = 0\n",
    "\treturn bb\n",
    "\n",
    "def generate_next(board):\n",
    "\tbb = np.array([get_board()])\n",
    "\tfor i in range(0, 8):\n",
    "\t\tfor j in range(0, 8):\n",
    "\t\t\tif (board[i, j] > 0):\n",
    "\t\t\t\tbb = np.vstack((bb, generate_branches(board, i, j)[1:]))\n",
    "\tif (len(bb) > 1):\n",
    "\t\treturn bb[1:]\n",
    "\tfor i in range(0, 8):\n",
    "\t\tfor j in range(0, 8):\n",
    "\t\t\tif (board[i, j] >= 1 and i < 7):\n",
    "\t\t\t\ttemp = board[i, j]\n",
    "\t\t\t\tif (j < 7):\n",
    "\t\t\t\t\tif (board[i+1, j+1] == 0):\n",
    "\t\t\t\t\t\tboard[i+1, j+1] = board[i, j]\n",
    "\t\t\t\t\t\tif (i+1 == 7):\n",
    "\t\t\t\t\t\t\tboard[i+1, j+1] = 3\n",
    "\t\t\t\t\t\tboard[i, j] = 0\n",
    "\t\t\t\t\t\tbb = np.vstack((bb, compress(board)))\n",
    "\t\t\t\t\t\tboard[i, j] = temp\n",
    "\t\t\t\t\t\tboard[i+1, j+1] = 0\n",
    "\t\t\t\tif (j > 0):\n",
    "\t\t\t\t\tif (board[i+1, j-1] == 0):\n",
    "\t\t\t\t\t\tboard[i+1, j-1] = board[i, j]\n",
    "\t\t\t\t\t\tif (i+1 == 7):\n",
    "\t\t\t\t\t\t\tboard[i+1, j-1] = 3\n",
    "\t\t\t\t\t\tboard[i, j] = 0\n",
    "\t\t\t\t\t\tbb = np.vstack((bb, compress(board)))\n",
    "\t\t\t\t\t\tboard[i, j] = temp\n",
    "\t\t\t\t\t\tboard[i+1, j-1] = 0\n",
    "\t\t\tif (board[i, j] == 3 and i > 0):\n",
    "\t\t\t\tif (j < 7):\n",
    "\t\t\t\t\tif (board[i-1, j+1] == 0):\n",
    "\t\t\t\t\t\tboard[i-1, j+1] = board[i, j]\n",
    "\t\t\t\t\t\tboard[i, j] = 0\n",
    "\t\t\t\t\t\tbb = np.vstack((bb, compress(board)))\n",
    "\t\t\t\t\t\tboard[i, j] = board[i-1, j+1]\n",
    "\t\t\t\t\t\tboard[i-1, j+1] = 0\n",
    "\t\t\t\telif (j > 0):\n",
    "\t\t\t\t\tif (board[i-1, j-1] == 0):\n",
    "\t\t\t\t\t\tboard[i-1, j-1] = board[i, j]\n",
    "\t\t\t\t\t\tboard[i, j] = 0\n",
    "\t\t\t\t\t\tbb = np.vstack((bb, compress(board)))\n",
    "\t\t\t\t\t\tboard[i, j] = board[i-1, j-1]\n",
    "\t\t\t\t\t\tboard[i-1, j-1] = 0\n",
    "\treturn bb[1:]\n",
    "\n",
    "def random_board():\n",
    "\tb = get_board()\n",
    "\tpromote = 0.9\n",
    "\tremove = 0.4\n",
    "\tadd = 0\n",
    "\tfor piece in b:\n",
    "\t\t# randomly promote, remove, or add piece\n",
    "\t\trand = np.random.random()\n",
    "\t\tif piece != 0 and rand > promote:\n",
    "\t\t\tpiece = piece * 3\n",
    "\t\t\tpromote = promote + 0.005\n",
    "\t\telif piece != 0 and rand < remove:\n",
    "\t\t\tpiece = 0\n",
    "\t\t\tremove = remove - 0.025\n",
    "\t\t\tadd = add + 0.05\n",
    "\t\telif piece == 0 and rand < add:\n",
    "\t\t\tif np.random.random() > 0.5:\n",
    "\t\t\t\tpiece = 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tpiece = -1\n",
    "\treturn b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc1eb17",
   "metadata": {},
   "source": [
    "## Initial Q-Table\n",
    "The approach that we are implementing here to build the **initial Q-table** is: \n",
    "#### 1. Heuristic metrics:\n",
    "Assign each piece on the board a score such that we can evaluate the overall position.The scores have been assigned intelligently,for instance, opponent's captured pieces and kings have been assigned higher scores than the pawns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb52580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "from keras.models import model_from_json\n",
    "\n",
    "def get_metrics(board): # returns a label and the 10 labeling metrics\n",
    "\tb = expand(board)\n",
    "\n",
    "\tcapped = num_captured(b)\n",
    "\tpotential = possible_moves(b) - possible_moves(reverse(b))\n",
    "\tmen = num_men(b) - num_men(-b)\n",
    "\tkings = num_kings(b) - num_kings(-b)\n",
    "\tcaps = capturables(b) - capturables(reverse(b))\n",
    "\tsemicaps = semicapturables(b)\n",
    "\tuncaps = uncapturables(b) - uncapturables(reverse(b))\n",
    "\tmid = at_middle(b) - at_middle(-b)\n",
    "\tfar = at_enemy(b) - at_enemy(reverse(b))\n",
    "\twon = game_winner(b)\n",
    "\n",
    "\tscore = 4*capped + potential + men + 3*kings + caps + 2*semicaps + 3*uncaps + 2*mid + 3*far + 100*won\n",
    "\tif (score < 0):\n",
    "\t\treturn np.array([-1, capped, potential, men, kings, caps, semicaps, uncaps, mid, far, won])\n",
    "\telse:\n",
    "\t\treturn np.array([1, capped, potential, men, kings, caps, semicaps, uncaps, mid, far, won])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b36103",
   "metadata": {},
   "source": [
    "#### 2. The Metrics model\n",
    "It is a generative model that takes as input an array of metrics (measured by the function get_metrics), then predicts the winning probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e2c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics model, which only looks at heuristic scoring metrics used for labeling\n",
    "metrics_model = Sequential()\n",
    "metrics_model.add(Dense(32, activation='relu', input_dim=10))\n",
    "metrics_model.add(Dense(16, activation='relu',\n",
    "                  kernel_regularizer=regularizers.l2(0.1)))\n",
    "\n",
    "# output is passed to relu() because labels are binary\n",
    "metrics_model.add(\n",
    "\tDense(1, activation='relu',  kernel_regularizer=regularizers.l2(0.1)))\n",
    "metrics_model.compile(\n",
    "\toptimizer='nadam', loss='binary_crossentropy', metrics=[\"acc\"])\n",
    "\n",
    "start_board = expand(np_board())\n",
    "boards_list = generate_next(start_board)\n",
    "branching_position = 0\n",
    "nmbr_generated_game = 10000\n",
    "while len(boards_list) < nmbr_generated_game:\n",
    "\ttemp = len(boards_list) - 1\n",
    "\tfor i in range(branching_position, len(boards_list)):\n",
    "\t\tif (possible_moves(reverse(expand(boards_list[i]))) > 0):\n",
    "\t\t\tboards_list = np.vstack((boards_list, generate_next(\n",
    "\t\t\t\treverse(expand(boards_list[i])))))\n",
    "\tbranching_position = temp\n",
    "\n",
    "# calculate/save heuristic metrics for each game state\n",
    "metrics = np.zeros((0, 10))\n",
    "winning = np.zeros((0, 1))\n",
    "\n",
    "for board in boards_list[:nmbr_generated_game]:\n",
    "\ttemp = get_metrics(board)\n",
    "\tmetrics = np.vstack((metrics, temp[1:]))\n",
    "\twinning = np.vstack((winning, temp[0]))\n",
    "\n",
    "# fit the metrics model\n",
    "history = metrics_model.fit(\n",
    "\tmetrics, winning, epochs=32, batch_size=64, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b778c2d",
   "metadata": {},
   "source": [
    "#### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac30e53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# History for accuracy\n",
    "plot.plot(history.history['acc'])\n",
    "plot.title('model accuracy')\n",
    "plot.ylabel('accuracy')\n",
    "plot.xlabel('epoch')\n",
    "plot.legend(['train'], loc='upper left')\n",
    "plot.show()\n",
    "\n",
    "# History for loss\n",
    "plot.plot(history.history['loss'])\n",
    "plot.title('model loss')\n",
    "plot.ylabel('loss')\n",
    "plot.xlabel('epoch')\n",
    "plot.legend(['train'], loc='upper left')\n",
    "plot.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6800669c",
   "metadata": {},
   "source": [
    "#### Instnatiate board model and heuristic metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73167c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Board model\n",
    "board_model = Sequential()\n",
    "\n",
    "# input dimensions is 32 board position values\n",
    "board_model.add(Dense(64, activation='relu', input_dim=32))\n",
    "\n",
    "# use regularizers, to prevent fitting noisy labels\n",
    "board_model.add(Dense(32, activation='relu',\n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "board_model.add(Dense(16, activation='relu',\n",
    "                kernel_regularizer=regularizers.l2(0.01)))  # 16\n",
    "board_model.add(Dense(8, activation='relu',\n",
    "                kernel_regularizer=regularizers.l2(0.01)))  # 8\n",
    "\n",
    "# output isn't squashed, because it might lose information\n",
    "board_model.add(Dense(1, activation='linear',\n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "board_model.compile(optimizer='nadam', loss='binary_crossentropy')\n",
    "\n",
    "# calculate heuristic metric for data\n",
    "metrics = np.zeros((0, 10))\n",
    "winning = np.zeros((0, 1))\n",
    "data = boards_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b67fbe",
   "metadata": {},
   "source": [
    "#### Fit the model and save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1e1fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for board in data:\n",
    "\ttemp = get_metrics(board)\n",
    "\tmetrics = np.vstack((metrics, temp[1:]))\n",
    "\twinning = np.zeros((0, 1))\n",
    "\n",
    "# calculate probilistic (noisy) labels\n",
    "probabilistic = metrics_model.predict_on_batch(metrics)\n",
    "\n",
    "# fit labels to {-1, 1}\n",
    "probabilistic = np.sign(probabilistic)\n",
    "\n",
    "# pass to the Board model\n",
    "board_model.fit(data, probabilistic, epochs=32, batch_size=64,\n",
    "                 verbose=0)\n",
    "\n",
    "board_json = board_model.to_json()\n",
    "with open('board_model.json', 'w') as json_file:\n",
    "\tjson_file.write(board_json)\n",
    "board_model.save_weights('board_model.h5')\n",
    "\n",
    "print('Checkers Board Model saved to: board_model.json/h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff8e6c9",
   "metadata": {},
   "source": [
    "After compiling the model, we loop through all the generated board positions. And, for each board we extract the metrics, then use the metrics model to predict the probability of winning from this board.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c35b275",
   "metadata": {},
   "source": [
    "#### Load the board model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e36a1d",
   "metadata": {},
   "source": [
    "This model represents a beginner level of checker expertise; the output of this model represents our initial Q-Value. Using this method to generate an initial Q-Value will make reinforcement learning considerably more efficient, because the trained board model is much better at evaluating board positions than the alternative, which is randomly selecting an evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f8e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('board_model.json', 'r')\n",
    "board_json = json_file.read()\n",
    "json_file.close()\n",
    "reinforced_model = model_from_json(board_json)\n",
    "reinforced_model.load_weights('board_model.h5')\n",
    "reinforced_model.compile(optimizer='adadelta', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a99c105",
   "metadata": {},
   "source": [
    "#### Reinforcing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2b84be",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('board_model.json', 'r')\n",
    "board_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "reinforced_model = model_from_json(board_json)\n",
    "reinforced_model.load_weights('board_model.h5')\n",
    "reinforced_model.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "\n",
    "data = np.zeros((1, 32))\n",
    "labels = np.zeros(1)\n",
    "win = lose = draw = 0\n",
    "winrates = []\n",
    "learning_rate = 0.5\n",
    "discount_factor = 0.95\n",
    "\n",
    "for gen in tqdm(range(0, 50),desc= \"processing\"):\n",
    "\tfor game in range(0, 200):\n",
    "\t\ttemp_data = np.zeros((1, 32))\n",
    "\t\tboard = expand(np_board())\n",
    "\t\tplayer = np.sign(np.random.random() - 0.5)\n",
    "\t\tturn = 0\n",
    "\t\twhile (True):\n",
    "\t\t\tmoved = False\n",
    "\t\t\tboards = np.zeros((0, 32))\n",
    "\t\t\tif (player == 1):\n",
    "\t\t\t\tboards = generate_next(board)\n",
    "\t\t\telse:\n",
    "\t\t\t\tboards = generate_next(reverse(board))\n",
    "\n",
    "\t\t\tscores = reinforced_model.predict_on_batch(boards)\n",
    "\t\t\tmax_index = np.argmax(scores)\n",
    "\t\t\tbest = boards[max_index]\n",
    "\n",
    "\t\t\tif (player == 1):\n",
    "\t\t\t\tboard = expand(best)\n",
    "\t\t\t\ttemp_data = np.vstack((temp_data, compress(board)))\n",
    "\t\t\telse:\n",
    "\t\t\t\tboard = reverse(expand(best))\n",
    "\n",
    "\t\t\tplayer = -player\n",
    "\n",
    "\t\t\t# punish losing games, reward winners  & drawish games reaching more than 200 turns\n",
    "\t\t\twinner = game_winner(board)\n",
    "\t\t\tif (winner == 1 or (winner == 0 and turn >= 200)):\n",
    "\t\t\t\tif winner == 1:\n",
    "\t\t\t\t\twin = win + 1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tdraw = draw + 1\n",
    "\t\t\t\treward = 10\n",
    "\t\t\t\told_prediction = reinforced_model.predict_on_batch(temp_data[1:])\n",
    "\t\t\t\toptimal_futur_value = np.ones(old_prediction.shape)\n",
    "\t\t\t\ttemp_labels = old_prediction + learning_rate * \\\n",
    "\t\t\t\t\t(reward + discount_factor * optimal_futur_value - old_prediction)\n",
    "\t\t\t\tdata = np.vstack((data, temp_data[1:]))\n",
    "\t\t\t\tlabels = np.vstack((labels, temp_labels))\n",
    "\t\t\t\tbreak\n",
    "\t\t\telif (winner == -1):\n",
    "\t\t\t\tlose = lose + 1\n",
    "\t\t\t\treward = -10\n",
    "\t\t\t\told_prediction = reinforced_model.predict_on_batch(temp_data[1:])\n",
    "\t\t\t\toptimal_futur_value = -1*np.ones(old_prediction.shape)\n",
    "\t\t\t\ttemp_labels = old_prediction + learning_rate * \\\n",
    "\t\t\t\t\t(reward + discount_factor * optimal_futur_value - old_prediction)\n",
    "\t\t\t\tdata = np.vstack((data, temp_data[1:]))\n",
    "\t\t\t\tlabels = np.vstack((labels, temp_labels))\n",
    "\t\t\t\tbreak\n",
    "\t\t\tturn = turn + 1\n",
    "\n",
    "\t\tif ((game+1) % 200 == 0):\n",
    "\t\t\treinforced_model.fit(data[1:], labels[1:],\n",
    "\t\t\t                     epochs=16, batch_size=256, verbose=0)\n",
    "\t\t\tdata = np.zeros((1, 32))\n",
    "\t\t\tlabels = np.zeros(1)\n",
    "\twinrate = int((win+draw)/(win+draw+lose)*100)\n",
    "\twinrates.append(winrate)\n",
    "\n",
    "\treinforced_model.save_weights('reinforced_model.h5')\n",
    "\n",
    "print('Checkers Board Model updated by reinforcement learning & saved to: reinforced_model.json/h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79feb09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generations = range(0, 50)\n",
    "print(\"Final win/draw rate : \" + str(winrates[49])+\"%\")\n",
    "plot.plot(generations, winrates)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22abaf93",
   "metadata": {},
   "source": [
    "#### Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3bd0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "json_file = open('board_model.json', 'r')\n",
    "board_json = json_file.read()\n",
    "json_file.close()\n",
    "reinforced_model = model_from_json(board_json)\n",
    "reinforced_model.load_weights('reinforced_model_v2.h5')\n",
    "reinforced_model.compile(optimizer='adadelta', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bb337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_move(board):\n",
    "  compressed_board = compress(board)\n",
    "  boards = np.zeros((0, 32))\n",
    "  boards = generate_next(board)\n",
    "  scores = reinforced_model.predict_on_batch(boards)\n",
    "  max_index = np.argmax(scores)\n",
    "  best = boards[max_index]\n",
    "  return best\n",
    "\n",
    "\n",
    "def print_board(board):\n",
    "  for row in board:\n",
    "    for square in row:\n",
    "      if square == 1:\n",
    "        caracter = \"|O\"\n",
    "      elif square == -1:\n",
    "        caracter = \"|X\"\n",
    "      else:\n",
    "        caracter = \"| \"\n",
    "      print(str(caracter), end='')\n",
    "    print('|')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda7af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_board = [1, 1, 1, 1,  1, 1, 1, 0,  1, 1, 0, 1,  0, 0, 1, 0,\n",
    "               0, 0, 0, -1,  0, 0, -1, -1,  -1, -1, -1, -1,  -1, -1, -1, -1]\n",
    "start_board = expand(start_board)\n",
    "next_board = expand(best_move(start_board))\n",
    "\n",
    "print(\"Starting position : \")\n",
    "print_board(start_board)\n",
    "\n",
    "print(\"\\nBest next move : \")\n",
    "print_board(next_board)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0ad8be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
