{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "626d221c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-05-20 09:43:29--  https://raw.githubusercontent.com/Btsan/CheckersBot/master/checkers.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14742 (14K) [text/plain]\n",
      "Saving to: 'checkers.py'\n",
      "\n",
      "checkers.py         100%[===================>]  14.40K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2023-05-20 09:43:29 (13.7 MB/s) - 'checkers.py' saved [14742/14742]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://raw.githubusercontent.com/Btsan/CheckersBot/master/checkers.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "897391e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.12.0-cp39-cp39-macosx_10_15_x86_64.whl (230.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.1/230.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy<1.24,>=1.22\n",
      "  Downloading numpy-1.23.5-cp39-cp39-macosx_10_9_x86_64.whl (18.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.54.2-cp39-cp39-macosx_10_10_universal2.whl (8.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.23.1-cp37-abi3-macosx_10_9_universal2.whl (400 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.3/400.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: setuptools in /Users/ayushkumartalreja/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (63.4.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/ayushkumartalreja/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.7.0)\n",
      "Collecting jax>=0.3.15\n",
      "  Downloading jax-0.4.10.tar.gz (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting keras<2.13,>=2.12.0\n",
      "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /Users/ayushkumartalreja/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.32.0-cp39-cp39-macosx_10_14_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0\n",
      "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /Users/ayushkumartalreja/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.3.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.0-py2.py3-none-macosx_10_9_x86_64.whl (26.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.5.9-py2.py3-none-any.whl (26 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/ayushkumartalreja/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.14.1)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: packaging in /Users/ayushkumartalreja/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "Collecting tensorboard<2.13,>=2.12\n",
      "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /Users/ayushkumartalreja/opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting ml-dtypes>=0.1.0\n",
      "  Downloading ml_dtypes-0.1.0-cp39-cp39-macosx_10_9_universal2.whl (317 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.9/317.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.7 in /Users/ayushkumartalreja/opt/anaconda3/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow) (1.9.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.18.1-py2.py3-none-any.whl (178 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/ayushkumartalreja/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/ayushkumartalreja/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.0.3)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.0-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /Users/ayushkumartalreja/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/ayushkumartalreja/opt/anaconda3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/ayushkumartalreja/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (1.26.11)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ayushkumartalreja/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ayushkumartalreja/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/ayushkumartalreja/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ayushkumartalreja/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/ayushkumartalreja/opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: jax\n",
      "  Building wheel for jax (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jax: filename=jax-0.4.10-py3-none-any.whl size=1480503 sha256=e183bd6ca616ae160f4992aaff53b4aef33687c2e7ff31be53eaea59c721cc2c\n",
      "  Stored in directory: /Users/ayushkumartalreja/Library/Caches/pip/wheels/e5/6c/70/7c6be85fa56f05480fe043bdf0d4f6ec316b122be21e098066\n",
      "Successfully built jax\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, protobuf, oauthlib, numpy, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, opt-einsum, ml-dtypes, google-auth, jax, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n",
      "    Uninstalling numpy-1.21.5:\n",
      "      Successfully uninstalled numpy-1.21.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 flatbuffers-23.5.9 gast-0.4.0 google-auth-2.18.1 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.54.2 jax-0.4.10 keras-2.12.0 libclang-16.0.0 ml-dtypes-0.1.0 numpy-1.23.5 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.1 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.12.3 tensorboard-data-server-0.7.0 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-io-gcs-filesystem-0.32.0 termcolor-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834afffa",
   "metadata": {},
   "source": [
    "#### Create get metrics function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7705e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras import regularizers\n",
    "import checkers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "def get_metrics(board):  # returns [label, 10 labeling metrics]\n",
    "\tb = expand(board)\n",
    "\n",
    "\tcapped = num_captured(b)\n",
    "\tpotential = possible_moves(b) - possible_moves(reverse(b))\n",
    "\tmen = num_men(b) - num_men(-b)\n",
    "\tkings = num_kings(b) - num_kings(-b)\n",
    "\tcaps = capturables(b) - capturables(reverse(b))\n",
    "\tsemicaps = semicapturables(b)\n",
    "\tuncaps = uncapturables(b) - uncapturables(reverse(b))\n",
    "\tmid = at_middle(b) - at_middle(-b)\n",
    "\tfar = at_enemy(b) - at_enemy(reverse(b))\n",
    "\twon = game_winner(b)\n",
    "\n",
    "\tscore = 4*capped + potential + men + 3*kings + \\\n",
    "\t\tcaps + 2*semicaps + 3*uncaps + 2*mid + 3*far + 100*won\n",
    "\tif (score < 0):\n",
    "\t\treturn np.array([-1, capped, potential, men, kings, caps, semicaps, uncaps, mid, far, won])\n",
    "\telse:\n",
    "\t\treturn np.array([1, capped, potential, men, kings, caps, semicaps, uncaps, mid, far, won])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b3e742",
   "metadata": {},
   "source": [
    "#### Create metrics_model & model heuristic metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e2c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics model, which only looks at heuristic scoring metrics used for labeling\n",
    "metrics_model = Sequential()\n",
    "metrics_model.add(Dense(32, activation='relu', input_dim=10))\n",
    "metrics_model.add(Dense(16, activation='relu',\n",
    "                  kernel_regularizer=regularizers.l2(0.1)))\n",
    "\n",
    "# output is passed to relu() because labels are binary\n",
    "metrics_model.add(\n",
    "\tDense(1, activation='relu',  kernel_regularizer=regularizers.l2(0.1)))\n",
    "metrics_model.compile(\n",
    "\toptimizer='nadam', loss='binary_crossentropy', metrics=[\"acc\"])\n",
    "\n",
    "start_board = checkers.expand(checkers.np_board())\n",
    "boards_list = checkers.generate_next(start_board)\n",
    "branching_position = 0\n",
    "nmbr_generated_game = 10000\n",
    "while len(boards_list) < nmbr_generated_game:\n",
    "\ttemp = len(boards_list) - 1\n",
    "\tfor i in range(branching_position, len(boards_list)):\n",
    "\t\tif (checkers.possible_moves(checkers.reverse(checkers.expand(boards_list[i]))) > 0):\n",
    "\t\t\tboards_list = np.vstack((boards_list, checkers.generate_next(\n",
    "\t\t\t\tcheckers.reverse(checkers.expand(boards_list[i])))))\n",
    "\tbranching_position = temp\n",
    "\n",
    "# calculate/save heuristic metrics for each game state\n",
    "metrics = np.zeros((0, 10))\n",
    "winning = np.zeros((0, 1))\n",
    "\n",
    "for board in boards_list[:nmbr_generated_game]:\n",
    "\ttemp = checkers.get_metrics(board)\n",
    "\tmetrics = np.vstack((metrics, temp[1:]))\n",
    "\twinning = np.vstack((winning, temp[0]))\n",
    "\n",
    "# fit the metrics model\n",
    "history = metrics_model.fit(\n",
    "\tmetrics, winning, epochs=32, batch_size=64, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b778c2d",
   "metadata": {},
   "source": [
    "#### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac30e53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# History for accuracy\n",
    "plot.plot(history.history['acc'])\n",
    "plot.plot(history.history['val_acc'])\n",
    "plot.title('model accuracy')\n",
    "plot.ylabel('accuracy')\n",
    "plot.xlabel('epoch')\n",
    "plot.legend(['train', 'validation'], loc='upper left')\n",
    "plot.show()\n",
    "\n",
    "# History for loss\n",
    "plot.plot(history.history['loss'])\n",
    "plot.plot(history.history['val_loss'])\n",
    "plot.title('model loss')\n",
    "plot.ylabel('loss')\n",
    "plot.xlabel('epoch')\n",
    "plot.legend(['train', 'validation'], loc='upper left')\n",
    "plot.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6800669c",
   "metadata": {},
   "source": [
    "#### Instnatiate board model and heuristic metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73167c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Board model\n",
    "board_model = Sequential()\n",
    "\n",
    "# input dimensions is 32 board position values\n",
    "board_model.add(Dense(64, activation='relu', input_dim=32))\n",
    "\n",
    "# use regularizers, to prevent fitting noisy labels\n",
    "board_model.add(Dense(32, activation='relu',\n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "board_model.add(Dense(16, activation='relu',\n",
    "                kernel_regularizer=regularizers.l2(0.01)))  # 16\n",
    "board_model.add(Dense(8, activation='relu',\n",
    "                kernel_regularizer=regularizers.l2(0.01)))  # 8\n",
    "\n",
    "# output isn't squashed, because it might lose information\n",
    "board_model.add(Dense(1, activation='linear',\n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "board_model.compile(optimizer='nadam', loss='binary_crossentropy')\n",
    "\n",
    "# calculate heuristic metric for data\n",
    "metrics = np.zeros((0, 10))\n",
    "winning = np.zeros((0, 1))\n",
    "data = boards_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b67fbe",
   "metadata": {},
   "source": [
    "#### Fit the model and save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1e1fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for board in data:\n",
    "\ttemp = checkers.get_metrics(board)\n",
    "\tmetrics = np.vstack((metrics, temp[1:]))\n",
    "\twinning = np.zeros((0, 1))\n",
    "\n",
    "# calculate probilistic (noisy) labels\n",
    "probabilistic = metrics_model.predict_on_batch(metrics)\n",
    "\n",
    "# fit labels to {-1, 1}\n",
    "probabilistic = np.sign(probabilistic)\n",
    "\n",
    "# calculate confidence score for each probabilistic label using error between probabilistic and weak label\n",
    "confidence = 1/(1 + np.absolute(winning - probabilistic[:, 0]))\n",
    "\n",
    "# pass to the Board model\n",
    "board_model.fit(data, probabilistic, epochs=32, batch_size=64,\n",
    "                sample_weight=confidence, verbose=0)\n",
    "\n",
    "board_json = board_model.to_json()\n",
    "with open('board_model.json', 'w') as json_file:\n",
    "\tjson_file.write(board_json)\n",
    "board_model.save_weights('board_model.h5')\n",
    "\n",
    "print('Checkers Board Model saved to: board_model.json/h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a99c105",
   "metadata": {},
   "source": [
    "#### Reinforcing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2b84be",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('board_model.json', 'r')\n",
    "board_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "reinforced_model = model_from_json(board_json)\n",
    "reinforced_model.load_weights('board_model.h5')\n",
    "reinforced_model.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "\n",
    "data = np.zeros((1, 32))\n",
    "labels = np.zeros(1)\n",
    "win = lose = draw = 0\n",
    "winrates = []\n",
    "learning_rate = 0.5\n",
    "discount_factor = 0.95\n",
    "\n",
    "for gen in range(0, 50):\n",
    "\tfor game in range(0, 200):\n",
    "\t\ttemp_data = np.zeros((1, 32))\n",
    "\t\tboard = checkers.expand(checkers.np_board())\n",
    "\t\tplayer = np.sign(np.random.random() - 0.5)\n",
    "\t\tturn = 0\n",
    "\t\twhile (True):\n",
    "\t\t\tmoved = False\n",
    "\t\t\tboards = np.zeros((0, 32))\n",
    "\t\t\tif (player == 1):\n",
    "\t\t\t\tboards = checkers.generate_next(board)\n",
    "\t\t\telse:\n",
    "\t\t\t\tboards = checkers.generate_next(checkers.reverse(board))\n",
    "\n",
    "\t\t\tscores = reinforced_model.predict_on_batch(boards)\n",
    "\t\t\tmax_index = np.argmax(scores)\n",
    "\t\t\tbest = boards[max_index]\n",
    "\n",
    "\t\t\tif (player == 1):\n",
    "\t\t\t\tboard = checkers.expand(best)\n",
    "\t\t\t\ttemp_data = np.vstack((temp_data, checkers.compress(board)))\n",
    "\t\t\telse:\n",
    "\t\t\t\tboard = checkers.reverse(checkers.expand(best))\n",
    "\n",
    "\t\t\tplayer = -player\n",
    "\n",
    "\t\t\t# punish losing games, reward winners  & drawish games reaching more than 200 turns\n",
    "\t\t\twinner = checkers.game_winner(board)\n",
    "\t\t\tif (winner == 1 or (winner == 0 and turn >= 200)):\n",
    "\t\t\t\tif winner == 1:\n",
    "\t\t\t\t\twin = win + 1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tdraw = draw + 1\n",
    "\t\t\t\treward = 10\n",
    "\t\t\t\told_prediction = reinforced_model.predict_on_batch(temp_data[1:])\n",
    "\t\t\t\toptimal_futur_value = np.ones(old_prediction.shape)\n",
    "\t\t\t\ttemp_labels = old_prediction + learning_rate * \\\n",
    "\t\t\t\t\t(reward + discount_factor * optimal_futur_value - old_prediction)\n",
    "\t\t\t\tdata = np.vstack((data, temp_data[1:]))\n",
    "\t\t\t\tlabels = np.vstack((labels, temp_labels))\n",
    "\t\t\t\tbreak\n",
    "\t\t\telif (winner == -1):\n",
    "\t\t\t\tlose = lose + 1\n",
    "\t\t\t\treward = -10\n",
    "\t\t\t\told_prediction = reinforced_model.predict_on_batch(temp_data[1:])\n",
    "\t\t\t\toptimal_futur_value = -1*np.ones(old_prediction.shape)\n",
    "\t\t\t\ttemp_labels = old_prediction + learning_rate * \\\n",
    "\t\t\t\t\t(reward + discount_factor * optimal_futur_value - old_prediction)\n",
    "\t\t\t\tdata = np.vstack((data, temp_data[1:]))\n",
    "\t\t\t\tlabels = np.vstack((labels, temp_labels))\n",
    "\t\t\t\tbreak\n",
    "\t\t\tturn = turn + 1\n",
    "\n",
    "\t\tif ((game+1) % 200 == 0):\n",
    "\t\t\treinforced_model.fit(data[1:], labels[1:],\n",
    "\t\t\t                     epochs=16, batch_size=256, verbose=0)\n",
    "\t\t\tdata = np.zeros((1, 32))\n",
    "\t\t\tlabels = np.zeros(1)\n",
    "\twinrate = int((win+draw)/(win+draw+lose)*100)\n",
    "\twinrates.append(winrate)\n",
    "\n",
    "\treinforced_model.save_weights('reinforced_model.h5')\n",
    "\n",
    "print('Checkers Board Model updated by reinforcement learning & saved to: reinforced_model.json/h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79feb09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generations = range(0, 500)\n",
    "print(\"Final win/draw rate : \" + str(winrates[499])+\"%\")\n",
    "plot.plot(generations, winrates)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22abaf93",
   "metadata": {},
   "source": [
    "#### Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bb337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_move(board):\n",
    "  compressed_board = checkers.compress(board)\n",
    "  boards = np.zeros((0, 32))\n",
    "  boards = checkers.generate_next(board)\n",
    "  scores = reinforced_model.predict_on_batch(boards)\n",
    "  max_index = np.argmax(scores)\n",
    "  best = boards[max_index]\n",
    "  return best\n",
    "\n",
    "\n",
    "def print_board(board):\n",
    "  for row in board:\n",
    "    for square in row:\n",
    "      if square == 1:\n",
    "        caracter = \"|O\"\n",
    "      elif square == -1:\n",
    "        caracter = \"|X\"\n",
    "      else:\n",
    "        caracter = \"| \"\n",
    "      print(str(caracter), end='')\n",
    "    print('|')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda7af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_board = [1, 1, 1, 1,  1, 1, 1, 0,  1, 0, 0, 1,  0, 0, 1, 0,\n",
    "               0, 0, 0, 0,  0, 0, -1, -1,  -1, -1, -1, -1,  -1, -1, -1, -1]\n",
    "start_board = checkers.expand(start_board)\n",
    "next_board = checkers.expand(best_move(start_board))\n",
    "\n",
    "print(\"Starting position : \")\n",
    "print_board(start_board)\n",
    "\n",
    "print(\"\\nBest next move : \")\n",
    "print_board(next_board)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
